{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0a1ccc",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "1. Check for duplicates\n",
    "2. Normalize hate speech score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c8cfe",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "861d239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "\n",
    "# Load the dataset from the Hugging Face Hub\n",
    "notebook_tqdm.tqdm.pandas()\n",
    "dataset = load_dataset('ucberkeley-dlab/measuring-hate-speech')\n",
    "\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df_raw = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "947cbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8 # TODO: factor this out everywhere\n",
    "TEST_RATIO = 0.2\n",
    "HATE_SPEECH_THRESHOLD_UNNORMALIZED = 0.5\n",
    "SUPPORTIVE_THRESHOLD_UNNORMALIZED = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d257149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1f6ab",
   "metadata": {},
   "source": [
    "# 2. Filtering & EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0657a97",
   "metadata": {},
   "source": [
    "Understanding:  \n",
    "TODO: what do the emotion columns actually mean?  \n",
    "TODO: what is \"status\"?  \n",
    "TODO: what is \"outfitms\" and \"infitms\"  \n",
    "TODO: what is \"hypothesis\"?\n",
    "TODO: how, if at all, is the annotator characteristics accounted for in the hate speech score?\n",
    "\n",
    "Filtering:\n",
    "TODO: Make list of filtering actions for report \n",
    "\n",
    "EDA:  \n",
    "TODO: Check out platform distributions  \n",
    "TODO: Sentiment methodology & distribution  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832b536b",
   "metadata": {},
   "source": [
    "### 2.0. Function definitions & variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1399e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hate_speech_score_histogram(df: pd.DataFrame, hate_threshold: float, supportive_threshold: float):\n",
    "    \"\"\"\n",
    "    Plots a histogram of the hate_speech_score with annotated lines at the thresholds\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to plot the histogram from\n",
    "        hate_threshold (float): The threshold for hate speech\n",
    "        supportive_threshold (float): The threshold for supportive speech\n",
    "\n",
    "    Returns:\n",
    "        None (plots the histogram)\n",
    "    \"\"\"\n",
    "\n",
    "    total_count = df.shape[0]\n",
    "    \n",
    "    # Calculate the amount of values below the supportive threshold\n",
    "    supportive_count = df[df['hate_speech_score'] < supportive_threshold].shape[0]\n",
    "\n",
    "    # Calculate the amount of values above the hate threshold\n",
    "    hate_count = df[df['hate_speech_score'] > hate_threshold].shape[0]\n",
    "\n",
    "    # Calculate the amount of values between the thresholds\n",
    "    neutral_count = df[(df['hate_speech_score'] >= supportive_threshold) & (df['hate_speech_score'] <= hate_threshold)].shape[0]\n",
    "\n",
    "    print(f\"Total count: {total_count}\")\n",
    "    print(f\"Supportive count: {supportive_count} ({supportive_count / total_count * 100:.2f}%)\")\n",
    "    print(f\"Hate count: {hate_count} ({hate_count / total_count * 100:.2f}%)\")\n",
    "    print(f\"Neutral count: {neutral_count} ({neutral_count / total_count * 100:.2f}%)\")\n",
    "\n",
    "    # Plot in histogram as well\n",
    "    plt.hist(df['hate_speech_score'], bins=100)\n",
    "    plt.axvline(hate_threshold, color='red', linestyle='--', label='Hate Speech Threshold')\n",
    "    plt.axvline(supportive_threshold, color='blue', linestyle='--', label='Supportive Threshold')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_target_columns_distribution(df: pd.DataFrame, target_cols: list[str]):\n",
    "    \"\"\"\n",
    "    Plots a barchart of the average value of the target columns for the hate speech observations\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to plot the distribution from\n",
    "        target_cols (list[str]): The columns to plot\n",
    "\n",
    "    Returns:\n",
    "        None (plots the distribution)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter to count hate speech only\n",
    "    hate_speech_df = df[df['is_hate_speech'] == 1]\n",
    "\n",
    "    # Calculate the mean value of the target columns for the hate speech observations and sort them descending\n",
    "    mean_values = hate_speech_df[target_cols].mean()\n",
    "    mean_values = mean_values.sort_values(ascending=False)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_values.plot(kind='bar')\n",
    "    plt.title('Percentage of hate speech columns targeting a specific group')\n",
    "    plt.xlabel('Target Column')\n",
    "    plt.ylabel('Percentage of hate speech')\n",
    "    plt.show()\n",
    "\n",
    "def plot_target_columns_detailed(df: pd.DataFrame, target_cols: list[str], fig_size: tuple[int, int] = (15, 30), y_max: float = 0.35):\n",
    "    \"\"\"\n",
    "    Plots a bar chart for each of the target columns with detailed breakdowns of sub-groups\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe to plot the distribution from\n",
    "        target_cols (list[str]): The columns to plot\n",
    "\n",
    "    Returns:\n",
    "        None (plots the distributions)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter to count hate speech only\n",
    "    hate_speech_df = df[df['is_hate_speech'] == 1]\n",
    "\n",
    "    # initalize axes to plot the 7 sub-groups in two rows of 3 and a last row of 1\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=2, figsize=fig_size)\n",
    "    # For each of the target columns, make a list of means of of hate speach targeting its sub-groups\n",
    "    for ax, col in zip(axes.flatten(), target_cols):\n",
    "\n",
    "        # Calculate the number of observations with a non-zero value for the target column\n",
    "        non_zero_count = hate_speech_df[col].value_counts()[1]\n",
    "\n",
    "        # identify all columns in the dataframe that starts with the target column name\n",
    "        sub_groups_column_names = [column for column in df.columns if column.startswith(col)]\n",
    "\n",
    "        # remove the original target column from the list\n",
    "        sub_groups_column_names.remove(col)\n",
    "        col_name = col.replace(\"target_\", \"\").title()\n",
    "\n",
    "        # calculate the mean values for each sub-group\n",
    "        sub_group_means = hate_speech_df[sub_groups_column_names].mean()\n",
    "        sub_group_means = sub_group_means.sort_values(ascending=False)\n",
    "\n",
    "        # remove the col string from the labels\n",
    "        labels = sub_group_means.index.str.replace((col + \"_\"), '')\n",
    "\n",
    "        # plot on the specific axis\n",
    "        sub_group_means.plot(kind='bar', ax=ax)\n",
    "        ax.set_xticklabels(labels)\n",
    "        ax.set_title(f'Percentage of hate speech targeting {col_name} by sub-group \\n(n={non_zero_count})')\n",
    "        ax.set_xlabel('Sub-group')\n",
    "        ax.set_ylabel('Percentage of hate speech')\n",
    "        ax.set_ylim(0, y_max)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "def inspect_for_cor(df, columns: list[str], plot_label: str, hate_speech_only: bool = True):\n",
    "\n",
    "    # filter for hate speech only if specified\n",
    "    if hate_speech_only:\n",
    "        df = df[df['is_hate_speech'] == 1]\n",
    "    \n",
    "    # Make a correlation matrix\n",
    "    corr_matrix = df[columns].corr()\n",
    "\n",
    "    # Plot the correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.title(f'Correlation Heatmap for {plot_label}')\n",
    "    plt.show()\n",
    "\n",
    "    # Make a pairplot of the columns\n",
    "    sns.pairplot(df[columns])\n",
    "    plt.title(f'Pairplot for {plot_label}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22853d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_cols = [\n",
    "    'insult',\n",
    "    'humiliate',\n",
    "    'status',\n",
    "    'dehumanize',\n",
    "    'violence',\n",
    "    'genocide'\n",
    "]\n",
    "\n",
    "cols_to_keep = [\n",
    "    'comment_id', \n",
    "    'text', \n",
    "    'hate_speech_score',\n",
    "    *aspect_cols,\n",
    "    *[col for col in df_raw.columns if col.startswith('target_')]\n",
    "]\n",
    "\n",
    "target_cols_lvl1 = [\n",
    "    'target_race',\n",
    "    'target_religion',\n",
    "    'target_origin',\n",
    "    'target_gender',\n",
    "    'target_sexuality',\n",
    "    'target_age',\n",
    "    'target_disability',    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37613ea6",
   "metadata": {},
   "source": [
    "### 2.1. Pre-filtering EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91890c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hate_speech_score_histogram(df_raw, HATE_SPEECH_THRESHOLD_UNNORMALIZED, SUPPORTIVE_THRESHOLD_UNNORMALIZED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f3881",
   "metadata": {},
   "source": [
    "### 2.2. Filtering & reformating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows based on the 'comment_id' column\n",
    "duplicate_texts = df_raw[df_raw.duplicated(subset='comment_id', keep=False)]\n",
    "print(f\"Number of duplicate texts: {duplicate_texts.shape[0]}\")\n",
    "duplicate_texts[['comment_id', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'comment_id' and count unique 'hate_speech_score' values per group\n",
    "score_check = df_raw.groupby(\"comment_id\")[\"hate_speech_score\"].nunique()\n",
    "\n",
    "# Find texts with more than one unique score\n",
    "inconsistent = score_check[score_check > 1]\n",
    "\n",
    "# Show how many inconsistencies there are\n",
    "print(f\"Number of 'comment_id' entries with inconsistent scores: {len(inconsistent)}\")\n",
    "\n",
    "# Optionally, view a few examples\n",
    "if not inconsistent.empty:\n",
    "    print(df_raw[df_raw[\"comment_id\"].isin(inconsistent.index)].sort_values(\"comment_id\").head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dfe2e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Select relevant columns\n",
    "df_relevant = df_raw[cols_to_keep].copy()\n",
    "\n",
    "# Step 2: Convert booleans to integers for mean calculation\n",
    "bool_cols = [col for col in df_relevant.columns if col.startswith('target_')]\n",
    "df_relevant[bool_cols] = df_relevant[bool_cols].astype(int)\n",
    "\n",
    "# Step 3: Group by 'comment_id' and 'text' to keep them in final output\n",
    "filtered_df = df_relevant.groupby(['comment_id', 'text']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bff2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = filtered_df['hate_speech_score'].min()  # e.g., -8.34\n",
    "max_score = filtered_df['hate_speech_score'].max()  # e.g., +6.3\n",
    "\n",
    "# replace hate speech core column with normalized column - [0, 1]\n",
    "filtered_df['hate_speech_score'] = (filtered_df['hate_speech_score'] - min_score) / (max_score - min_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f321de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the thresholds given by the dataset authors\n",
    "HATE_SPEECH_THRESHOLD_NORMALIZED = (0.5 - min_score) / (max_score - min_score)  \n",
    "SUPPORTIVE_THRESHOLD_NORMALIZED = (-1 - min_score) / (max_score - min_score)\n",
    "\n",
    "# Add binary columns for hate speech\n",
    "filtered_df.insert(filtered_df.columns.get_loc('hate_speech_score') + 1, 'is_hate_speech', (filtered_df['hate_speech_score'] > HATE_SPEECH_THRESHOLD_NORMALIZED).astype(int))\n",
    "\n",
    "# Print new normalized thresholds \n",
    "print(f\"Threshold for hate speech: {HATE_SPEECH_THRESHOLD_NORMALIZED:.3f} -> Equivalent to {0.5} on the original scale\")\n",
    "print(f\"Threshold for counter speech: {SUPPORTIVE_THRESHOLD_NORMALIZED:.3f} -> Equivalent to {-1} on the original scale\")\n",
    "print(f\"Between the two thresholds: {HATE_SPEECH_THRESHOLD_NORMALIZED:.3f} and {SUPPORTIVE_THRESHOLD_NORMALIZED:.3f} -> Equivalent to {0.5} and {-1} on the original scale which is the unambiguous region\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e1c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34e919",
   "metadata": {},
   "source": [
    "### 2.3. Post-filtering EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35914d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hate_speech_score_histogram(filtered_df, HATE_SPEECH_THRESHOLD_NORMALIZED, SUPPORTIVE_THRESHOLD_NORMALIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_target_columns_distribution(filtered_df, target_cols_lvl1)\n",
    "plot_target_columns_detailed(filtered_df, target_cols_lvl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_for_cor(filtered_df, aspect_cols, 'Aspect Columns')\n",
    "inspect_for_cor(filtered_df, target_cols_lvl1, 'Target Columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc0b7c",
   "metadata": {},
   "source": [
    "# 3. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a64241",
   "metadata": {},
   "source": [
    "### 3.1. BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67b6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for Bag of Words (BoW) representation\n",
    "bow_df = agg_df.copy()\n",
    "\n",
    "# Releveant columns\n",
    "cols_to_keep = ['text', 'is_hate_speech']\n",
    "\n",
    "# Select relevant columns\n",
    "bow_df = bow_df[cols_to_keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc79ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = bow_df['is_hate_speech'].value_counts()\n",
    "label_percentage = bow_df['is_hate_speech'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)\n",
    "print(\"\\nLabel Percentage Distribution:\")\n",
    "print(label_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36de96e",
   "metadata": {},
   "source": [
    "## 3.1 Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eb1c6f",
   "metadata": {},
   "source": [
    "## TODO: Maybe remove preprocessing from pipepine to just have it done once for \"Part 2\" of Assignment 3 approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76203444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary NLTK resources\n",
    "for resource in ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger']:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "# Tokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"\n",
    "    Convert the part of speech tag to a format that WordNet lemmatizer can understand.\n",
    "    starts with 'J' for adjectives, 'V' for verbs, 'N' for nouns, and 'R' for adverbs.\n",
    "    Args:\n",
    "        tag (str): The part of speech tag.\n",
    "    Returns:\n",
    "        str: The WordNet part of speech tag.\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "def is_ascii(token):\n",
    "    return all(ord(c) < 128 for c in token)\n",
    "\n",
    "def remove_repeated_chars(token, threshold=3):\n",
    "    return re.sub(r'(.)\\1{' + str(threshold) + r',}', r'\\1', token)\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    Preprocess the text by tokenizing, removing punctuation, stop words,\n",
    "    and lemmatizing the words.\n",
    "    Args:\n",
    "        text (str): The text to preprocess.\n",
    "    Returns:\n",
    "        str: The preprocessed text.\n",
    "    Example:\n",
    "        >>> preprocess(\"This is an EXAMPLE sentence!!!.\")\n",
    "        'example sentence'\n",
    "        \n",
    "    \"\"\"\n",
    "    tokens = tknzr.tokenize(text) # Tokenize the text\n",
    "    tokens = [word.lower() for word in tokens if word not in string.punctuation] # Remove punctuation\n",
    "    tokens = [word for word in tokens if word not in stop_words] # Remove stop words\n",
    "    tokens = [remove_repeated_chars(word) for word in tokens] # Remove repeated characters, ex: \"loooove\" -> \"love\"\n",
    "    tokens = [word for word in tokens if len(word) >= 2 and is_ascii(word)]  # Filter by length and ASCII\n",
    "    pos_tags = pos_tag(tokens) # Get part of speech tags\n",
    "    lemmatized = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in pos_tags] # Lemmatize the words using the part of speech tags\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ccfaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51bf864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline_bow = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2904909",
   "metadata": {},
   "source": [
    "## 3.2 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d9e567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = bow_df['text']\n",
    "y = bow_df['is_hate_speech']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264239dd",
   "metadata": {},
   "source": [
    "## 3.3 Fit model to training set - BoW + LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline_bow.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bow = pipeline_bow.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report_bow = classification_report(y_test, y_pred_bow, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31455156",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append({\n",
    "    'model': 'BoW + LogisticRegression',\n",
    "    'precision_hate': report_bow['1']['precision'],\n",
    "    'recall_hate': report_bow['1']['recall'],\n",
    "    'f1_hate': report_bow['1']['f1-score'],\n",
    "    'accuracy': report_bow['accuracy']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa679c",
   "metadata": {},
   "source": [
    "## 3.4 Fit model to training set - TFIDF + LogRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "pipeline_tfidf.fit(X_train, y_train)\n",
    "y_pred_tfidf = pipeline_tfidf.predict(X_test)\n",
    "\n",
    "report_tfidf = classification_report(y_test, y_pred_tfidf, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01aeb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    'model': 'TF-IDF + LogisticRegression',\n",
    "    'precision_hate': report_tfidf['1']['precision'],\n",
    "    'recall_hate': report_tfidf['1']['recall'],\n",
    "    'f1_hate': report_tfidf['1']['f1-score'],\n",
    "    'accuracy': report_tfidf['accuracy']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb087e",
   "metadata": {},
   "source": [
    "## 3.4.1 Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a76abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipeline_tuned = Pipeline([\n",
    "    ('preprocessor', TextPreprocessor()),\n",
    "    ('vectorizer', TfidfVectorizer()),  # or CountVectorizer()\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1,1), (1,2)],\n",
    "    'vectorizer__max_features': [5000, 10000],\n",
    "    'vectorizer__max_df': [0.75, 0.9],\n",
    "    'classifier__C': [0.1, 1],\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear']  # Needed for 'l1' penalty\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline_tuned,\n",
    "    param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='f1',  # use 'f1' to focus on hate speech detection\n",
    "    verbose=2, # print progress\n",
    "    n_jobs=1  # use all CPU cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcadc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params:\", grid_search.best_params_)\n",
    "print(\"Best cross-validated F1 score:\", grid_search.best_score_)\n",
    "\n",
    "# Use best model to predict test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45021dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
